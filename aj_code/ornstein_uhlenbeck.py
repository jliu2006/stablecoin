# -*- coding: utf-8 -*-
"""Ornstein_Uhlenbeck.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HshqI2A-TqCIEY-pu3cE_uHtvuK1oYCf
"""

!pip install torchsde pysr

import torch
import torchsde
import matplotlib.pyplot as plt

import torch
import torchsde

mu = 100
sigma = 3.
theta = 3.

class OU_Drift(torch.nn.Module):
    def __init__(self, mu, theta):
        super().__init__()
        self.mu = mu
        self.theta = theta

    def forward(self, t, y):
        return self.theta * (self.mu - y)

class OU_Diffusion(torch.nn.Module):
    def __init__(self, sigma):
        super().__init__()
        self.sigma = sigma

    def forward(self, t, y):
        return self.sigma * torch.ones_like(y)

drift = OU_Drift(mu, theta)
diffusion = OU_Diffusion(sigma)

class OU_SDE(torch.nn.Module):
    def __init__(self, drift, diffusion):
        super().__init__()
        self.drift = drift
        self.diffusion = diffusion
        self.noise_type = "diagonal"
        self.sde_type = "ito"

    def f(self, t, y):
        return self.drift(t, y)

    def g(self, t, y):
        return self.diffusion(t, y)

sde = OU_SDE(drift, diffusion)

t_span = torch.linspace(0, 2, 1000)

y0 = torch.zeros(500, 1)

with torch.no_grad():
    paths = torchsde.sdeint(sde, y0, t_span)

print("Shape of simulated paths:", paths.shape)

import torch.nn as nn
import torchsde
import torch

class NeuralSDE(torch.nn.Module):
    def __init__(self, hidden_size, output_size):
        super(NeuralSDE, self).__init__()
        self.noise_type = "diagonal"
        self.sde_type = "ito"


        self.drift_nn = nn.Sequential(
            nn.Linear(output_size, hidden_size),
            nn.ReLU(),
            nn.Linear(hidden_size, output_size)
        )

        self.diffusion_nn = nn.Sequential(
            nn.Linear(output_size, hidden_size),
            nn.ReLU(),
            nn.Linear(hidden_size, output_size)
        )

    def f(self, t, y):
        return self.drift_nn(y)

    def g(self, t, y):
        return self.diffusion_nn(y)


    def forward(self, ts, y0):
        return torchsde.sdeint(self, y0, ts, dt=0.01,method = 'euler')

hidden_size = 512
output_size = 1

model = NeuralSDE(hidden_size, output_size)


print("Neural SDE model defined with f and g methods calling internal networks.")

import torch.optim as optim
import torch.nn as nn

target_paths = paths

criterion = nn.MSELoss()

optimizer = optim.Adam(model.parameters(), lr=0.001)

print("Loss function and optimizer defined.")

num_epochs = 3000

y0_train = target_paths[0, :, :]

t_span_train = t_span

print(f"Starting training for {num_epochs} epochs...")

for epoch in range(num_epochs):
    optimizer.zero_grad()

    predicted_paths = model(t_span_train, y0_train)

    loss = criterion(predicted_paths, target_paths)

    loss.backward()

    optimizer.step()

    if (epoch + 1) % 100 == 0:
        print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.6f}")

print("Training finished.")

# Select one path from the initial conditions
# y0_single_path = y0_train[0, :].unsqueeze(0) # Add a batch dimension

# Generate predictions for this single path using the trained model
with torch.no_grad():
    predicted_paths_all = model(t_span_train, y0_train) # Predict for all initial conditions

# Plot the predicted path and a few original paths
plt.figure(figsize=(10, 6))

# Plot all original paths
for i in range(target_paths.shape[1]):
    plt.plot(t_span_train.numpy(), target_paths[:, i, 0].numpy(), color='gray', alpha=0.5, linestyle='--')

# Plot all predicted paths
for i in range(predicted_paths_all.shape[1]):
    plt.plot(t_span_train.numpy(), predicted_paths_all[:, i, 0].numpy(), color='red', alpha=0.5) # Plotting all predicted paths with some transparency


plt.xlabel('Time')
plt.ylabel('Y')
plt.title('Predicted Paths vs Original Paths')
# plt.legend() # Removing legend as there are too many lines
plt.grid(True)
plt.show()

# Generate a range of y values to evaluate the drift function
y_range = torch.linspace(torch.min(target_paths).item(), torch.max(target_paths).item(), 10000).unsqueeze(1)

# Evaluate the learned drift function over the y range
# We can use any t since the learned drift doesn't depend on t in this model
t_eval = torch.tensor([0.0])
with torch.no_grad():
    learned_drift = model.f(t_eval, y_range)

# Calculate the true drift function for comparison using the formula
true_drift_formula = theta * (mu - y_range)


# Plot the learned and true drift functions
plt.figure(figsize=(10, 6))
plt.plot(y_range.numpy()[500:], learned_drift.numpy()[500:], label='Learned Drift (model.f)', color='red')
plt.plot(y_range.numpy(), true_drift_formula.numpy(), label='True Drift Formula: θ(μ - y)', color='blue', linestyle='--')

plt.xlabel('Y')
plt.ylabel('Drift')
plt.title('Learned Drift Function vs True Drift Function')
plt.legend()
plt.grid(True)
plt.show()

from pysr import PySRRegressor

# Exclude the first 500 values from y_range and learned_drift
y_range_sliced = y_range[500:]
learned_drift_sliced = learned_drift[500:]

# Initialize the PySR regressor
# You might need to adjust the parameters based on the complexity of the learned function
model_sr = PySRRegressor(
    model_selection="best",  # Selects the best model based on complexity vs accuracy
    niterations=100,         # Number of iterations to run
    binary_operators=["+", "*", "-", "/"],
    unary_operators=["neg", "cos", "sin", "exp", "log"],
    # You can add custom operators here if needed, e.g., extra_unary_operators={"sqrt": "sqrt"}
    # You might also want to specify complexity_of_operators and complexity_of_constants
)

# Fit the model to the sliced data
# PySR expects input X to be a 2D array, and y to be a 1D array
# We need to reshape y_range_sliced to be 2D and squeeze learned_drift_sliced to be 1D
model_sr.fit(y_range_sliced.detach().numpy().reshape(-1, 1), learned_drift_sliced.detach().numpy().squeeze())

# Print the discovered equations
print(model_sr.equations_)

from pysr import PySRRegressor

# Initialize the PySR regressor for the true drift function
# We can use similar parameters as before, but may need to adjust based on the expected complexity
model_sr_true = PySRRegressor(
    model_selection="best",  # Selects the best model based on complexity vs accuracy
    niterations=100,         # Number of iterations to run
    binary_operators=["+", "*", "-", "/"],
    unary_operators=["neg"], # The true drift is linear, so we only need negation
    # You can add custom operators here if needed
    # You might also want to specify complexity_of_operators and complexity_of_constants
)

# Fit the model to the true drift data
# PySR expects input X to be a 2D array, and y to be a 1D array
# We need to reshape y_range to be 2D and squeeze true_drift_formula to be 1D
model_sr_true.fit(y_range.detach().numpy().reshape(-1, 1), true_drift_formula.detach().numpy().squeeze())

# Print the discovered equations for the true drift
print("Discovered equations for the true drift:")
print(model_sr_true.equations_)
