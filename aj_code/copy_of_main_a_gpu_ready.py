# -*- coding: utf-8 -*-
"""Copy of Main_A_GPU_Ready.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-ko9-DZOOX3rUt8pUy0LFe_j6ttysZxr
"""

import torch
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(device)
!pip install torchsde
import numpy as np
import pandas as pd
import yfinance as yf
import pywt
from sklearn.preprocessing import MinMaxScaler,StandardScaler
from sklearn.model_selection import train_test_split
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.utils as utils
from torch.utils.data import TensorDataset,DataLoader
import torchsde
import matplotlib.pyplot as plt
from scipy.optimize import curve_fit

def preprocess_combined(data, lookback, time_step, batch_size=64, split_ratio=0.65):
    # Extract features and target
    features = data.values[:, :]
    target = data.values[:, 1]

    # Initialize scalers
    features_scaler = MinMaxScaler(feature_range=(0, 1))
    target_scaler = MinMaxScaler(feature_range=(0, 1))

    # Scale the data
    features_scaled = features_scaler.fit_transform(features)
    target_scaled = target_scaler.fit_transform(target.reshape(-1, 1))

    # Create lookback sequences
    X, y = [], []
    for i in range(len(features_scaled) - lookback - time_step):
        X.append(features_scaled[i:(i + lookback)])
        y.append(target_scaled[i + lookback + time_step])

    X = np.array(X)
    y = np.array(y)

    # Split into train and test
    split = int(split_ratio * len(X))
    X_train, X_test = X[:split], X[split:]
    y_train, y_test = y[:split], y[split:]

    # Convert to tensors
    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)
    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)
    y_train_tensor = torch.tensor(y_train, dtype=torch.float32)
    y_test_tensor = torch.tensor(y_test, dtype=torch.float32)

    # Create datasets and loaders
    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)
    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)

    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

    return train_loader, test_loader, features_scaler, target_scaler

t1 = 'USDT-USD'
t2 = 'COP=X'
START_DATE = '2020-09-01'
END_DATE = '2025-07-02'
ou_data = yf.download(t1, start=START_DATE, end=END_DATE)['Close'].rolling(window=30).mean()

gm_data = yf.download(t2,  start=START_DATE, end=END_DATE)['Close'].rolling(window=1).mean()

combined_data = pd.concat((ou_data, gm_data), axis=1, join='outer')


combined_data.dropna(inplace=True)
display(combined_data.head())

T = 1
DT = 1 / 252
N = int(T / DT)
t = np.linspace(0, T, N)

N_simulations = 100
SHOCK_STD_MULTIPPLIER = -100
SHOCK_DURATION = 1
WAVELET = 'db2'
LOOKBACK = 42
SHOCK_START_INDEX = 45
WINDOW_BEFORE = LOOKBACK
WINDOW_AFTER = SHOCK_DURATION +2

lookback = 45
time_step = 1
train_loader_combined, test_loader_combined, features_scaler_combined, target_scaler_combined = preprocess_combined(combined_data, lookback = lookback, time_step = time_step)

print("Preprocessing with combined data complete.")

class NeuralSDE(torch.nn.Module):
    def __init__(self, hidden_size, input_features, output_size, lookback):
        super(NeuralSDE, self).__init__()
        self.noise_type = "diagonal"
        self.sde_type = "ito"
        self.lookback = lookback
        self.input_features = input_features
        self.output_size = output_size
        self.drift_lstm = nn.LSTM(input_features, hidden_size, batch_first=True)
        self.diffusion_lstm = nn.LSTM(input_features, hidden_size, batch_first=True)

        self.drift_linear = nn.Linear(hidden_size + output_size, output_size)
        self.diffusion_linear = nn.Linear(hidden_size + output_size, output_size)

        self.register_buffer('_lstm_hidden_buffer', None)
    def f(self, t, y):
        lstm_hidden = self._lstm_hidden_buffer
        if lstm_hidden is None:
             raise RuntimeError("LSTM hidden state buffer is not set. Call forward with input_sequence first.")

        combined_input = torch.cat((lstm_hidden, y), dim=1)

        return self.drift_linear(combined_input)
    def g(self, t, y):
        lstm_hidden = self._lstm_hidden_buffer
        if lstm_hidden is None:
             raise RuntimeError("LSTM hidden state buffer is not set. Call forward with input_sequence first.")

        combined_input = torch.cat((lstm_hidden, y), dim=1)

        return self.diffusion_linear(combined_input)


    def forward(self, ts, y0, input_sequence):
        lstm_output, (lstm_hidden, _) = self.drift_lstm(input_sequence)
        self._lstm_hidden_buffer = lstm_hidden.squeeze(0)

        solutions = torchsde.sdeint(self, y0, ts, dt=0.01, method='euler')

        self._lstm_hidden_buffer = None

        return solutions

hidden_size = 1024
input_features = 2
output_size = 1

model = NeuralSDE(hidden_size, input_features, output_size, lookback)

print("Neural SDE model defined with LSTM layers only.")
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=1e-5)

num_epochs = 5

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    for inputs, targets in train_loader_combined:
        optimizer.zero_grad()
        y0 = inputs[:, 0, 1].unsqueeze(1)

        ts = torch.linspace(0, 1, inputs.shape[1])

        solutions = model(ts, y0, inputs)

        predictions = solutions[-1]

        loss = criterion(predictions, targets)
        print(loss)
        loss.backward()
        utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        optimizer.step()

        running_loss += loss.item()

    print(f"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader_combined)}")

print("Training finished.")
model.eval()

actual_values_combined = []
predicted_values_combined = []

with torch.no_grad():
    for inputs, targets in test_loader_combined:
        y0 = inputs[:, 0, 1].unsqueeze(1)

        ts = torch.linspace(0, 1, inputs.shape[1])

        solutions = model(ts, y0, inputs)

        predictions = solutions[-1]

        actual_values_combined.append(targets.squeeze().numpy())
        predicted_values_combined.append(predictions.squeeze().numpy())

actual_values_combined = np.concatenate(actual_values_combined)
predicted_values_combined = np.concatenate(predicted_values_combined)

print("Prediction generation complete for combined data.")
lookback = 14

actual_values_original_scale_combined = target_scaler_combined.inverse_transform(actual_values_combined.reshape(-1, 1))
predicted_values_original_scale_combined = target_scaler_combined.inverse_transform(predicted_values_combined.reshape(-1, 1))

shifted_predicted_values = predicted_values_original_scale_combined[:-lookback]
corresponding_actual_values = actual_values_original_scale_combined[lookback:]

plt.figure(figsize=(14, 7))
plt.plot(corresponding_actual_values, label='Actual Ruble Price')
plt.plot(shifted_predicted_values, label=f'Predicted Ruble Price (Shifted Left by {lookback} Days)')
plt.title('Actual vs Predicted Ruble Prices (Test Set, Shifted)')
plt.xlabel('Time Steps')
plt.ylabel('Ruble Price')
plt.legend()
plt.grid(True)
plt.show()